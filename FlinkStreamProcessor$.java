object FlinkStreamProcessor{
        def main(args:Array[String]):Unit={

        // Cr√©er l'environnement d'ex√©cution Flink
        val env=StreamExecutionEnvironment.getExecutionEnvironment

        println("üöÄ Initialisation du job Flink...")

        // Configuration Kafka Source
        val kafkaSource=KafkaSource.builder[String]()
        .setBootstrapServers("localhost:9092")
        .setTopics("quickstart-eventsout")
        .setGroupId("flink-consumer-group")
        .setStartingOffsets(OffsetsInitializer.earliest())
        .setValueOnlyDeserializer(new SimpleStringSchema())
        .build()

        // CORRECTION : Avec le bon WatermarkStrategy
        val kafkaStream=env.fromSource(
        kafkaSource,
        WatermarkStrategy.noWatermarks(), // ‚úÖ Correct
        "Kafka Source"
        )

        // Traitement des donn√©es
        val processedStream=kafkaStream
        .map{jsonString=>
        try{
        // Log simple pour debug
        println(s"üì• Message re√ßu: $jsonString")
        jsonString
        }catch{
        case e:Exception=>
        println(s"‚ùå Erreur de parsing: ${e.getMessage}")
        s"""{"error": "Parse error", "message": "${e.getMessage}", "raw": "$jsonString"}"""
        }
        }
        .filter(_.nonEmpty)

        // Afficher dans la console pour tester
        processedStream.print()

        // Ex√©cuter le job
        println("‚úÖ Job Flink configur√© - D√©marrage de l'ex√©cution...")
        env.execute("Flink Kafka Processor")
        }
        }
